{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "configfilepath = '../data/yolov3.cfg.txt'\n",
    "weightfilepath = '../data/yolov3.weights'\n",
    "video_path = '../data/videos/'\n",
    "video_name = 'mumbai_traffic.mp4'\n",
    "video_path_comp = video_path + video_name\n",
    "input_image_path = '../data/test.jpg'\n",
    "model_image_shape = (416,416,3)\n",
    "max_output_size = 40\n",
    "max_output_size_per_class= 20\n",
    "iou_thresh = 0.5\n",
    "confidence_thresh = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUsing configuration and weights from https://pjreddie.com/darknet/yolo/\\nspecifically --> YOLOv3-416\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "block_list will store all blocks in a list\n",
    "each block is a dictionary describing the execution at that step\n",
    "\"\"\"\n",
    "def get_blocks(configfilepath):\n",
    "  \n",
    "  block_list = []\n",
    "  with open(configfilepath, 'r') as file:\n",
    "        lines = [line.rstrip('\\n') for line in file if line != '\\n' and line[0] != '#']\n",
    "  presentblock = {}\n",
    "  for line in lines:\n",
    "\n",
    "    if line[0] == '[':\n",
    "      # print(line)\n",
    "      if presentblock != {}:\n",
    "        block_list.append(presentblock)\n",
    "        presentblock = {}\n",
    "      presentblock['type'] = line[1:-1].rstrip()\n",
    "    else:\n",
    "        category,value = line.split('=')\n",
    "        presentblock[category.rstrip()] = value.lstrip()\n",
    "  if presentblock != {}:\n",
    "    block_list.append(presentblock)\n",
    "    presentblock = {}\n",
    "\n",
    "  return block_list\n",
    "\n",
    "\"\"\"\n",
    "Using configuration and weights from https://pjreddie.com/darknet/yolo/\n",
    "specifically --> YOLOv3-416\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(configfilepath,model_image_shape):\n",
    "  \n",
    "  block_list = get_blocks(configfilepath)\n",
    "  parameter_block = block_list[0]\n",
    "  x = input = tf.keras.Input(shape =(model_image_shape))\n",
    "  x = x / 255.0\n",
    "  layers_cache = []\n",
    "  out_pred = []\n",
    "  scale = 0\n",
    "  # print('a')\n",
    "  # print(len(block_list))\n",
    "  for i,block in enumerate(block_list[1:]):\n",
    "    \n",
    "    if block['type'] == 'convolutional':\n",
    "      # print('b')\n",
    "      filters = int(block['filters'])\n",
    "      kernel_size = int(block['size'])\n",
    "      strides = int(block['stride'])\n",
    "      activation=block['activation']\n",
    "      if strides > 1:\n",
    "        x = tf.keras.layers.ZeroPadding2D(((1,0),(1,0)))(x)   #Padding done as --> (top,bottom),(left,right) top and left favoured by model thus padded\n",
    "      x = tf.keras.layers.Conv2D(filters = filters,kernel_size = kernel_size,strides = strides,padding = 'valid' if strides > 1 else 'same',use_bias = False if 'batch_normalize' in block else True,name = f'conv_{i}')(x)\n",
    "      if 'batch_normalize' in block:\n",
    "        x = tf.keras.layers.BatchNormalization(name = f'batch_norm_{i}')(x)\n",
    "      if activation == 'leaky':\n",
    "        x = tf.keras.layers.LeakyReLU(alpha = 0.1,name = f'leakyRLU_{i}')(x)\n",
    "      ##alpha is actually parameterblocks's hue parameter i.e parameter_block['hue']\n",
    "    elif block['type'] == 'shortcut':\n",
    "      from_ = int(block['from'])\n",
    "      # print(from_)\n",
    "      ######MARKER##############################################\n",
    "      x = tf.keras.layers.add([x, layers_cache[from_]]) ##since from is -3 we will get 3rd element in list from Behind\n",
    "    elif block['type'] == 'upsample':\n",
    "      x = tf.keras.layers.UpSampling2D(size=int(block['stride']))(x)\n",
    "    \n",
    "    elif block['type'] == 'route':\n",
    "\n",
    "        block['layers'] = block['layers'].split(',')\n",
    "        if len(block['layers']) > 1:\n",
    "          \n",
    "          rel = int(block['layers'][0])\n",
    "          abs = int(block['layers'][1])\n",
    "          ###############MARKER########################\n",
    "          x= tf.concat([layers_cache[rel],layers_cache[abs]],axis = -1)\n",
    "        else:\n",
    "          rel = int(block['layers'][0])\n",
    "          x = layers_cache[rel] \n",
    "\n",
    "    elif block['type'] == 'yolo':\n",
    "      # print('c')\n",
    "      mask = block[\"mask\"].split(\",\")\n",
    "      mask = [int(x) for x in mask]\n",
    "      anchors = block[\"anchors\"].split(\",\")\n",
    "      anchors = [int(a) for a in anchors]\n",
    "      anchors = [(anchors[i], anchors[i + 1]) for i in range(0, len(anchors), 2)]\n",
    "      anchors = [anchors[i] for i in mask]\n",
    "      n_anchors = len(anchors)\n",
    "      num_classes = int(block['classes'])\n",
    "      # (batch_size x  grid_size x grid_size x (num_anchors)*(5 + num_classes)) --> Shape of Output of yolo\n",
    "      out_shape = x.get_shape().as_list()\n",
    "      x = tf.reshape(x, [-1, n_anchors * out_shape[1] * out_shape[2],5 + num_classes])\n",
    "\n",
    "      # We can infer what is where in bbox\n",
    "      box_centers = x[:, :, 0:2]\n",
    "      box_shapes = x[:, :, 2:4]\n",
    "      confidence = x[:, :, 4:5]\n",
    "      classes = x[:, :, 5:num_classes + 5]\n",
    "      box_centers = tf.sigmoid(box_centers)\n",
    "      confidence = tf.sigmoid(confidence)\n",
    "      classes = tf.sigmoid(classes)\n",
    "\n",
    "      anchors = tf.tile(anchors, [out_shape[1] * out_shape[2], 1])\n",
    "      box_shapes = tf.exp(box_shapes) * tf.cast(anchors, dtype=tf.float32)\n",
    "\n",
    "      x = tf.range(out_shape[1], dtype=tf.float32)\n",
    "      y = tf.range(out_shape[2], dtype=tf.float32)\n",
    "      cx, cy = tf.meshgrid(x, y)\n",
    "      cx = tf.reshape(cx, (-1, 1))\n",
    "      cy = tf.reshape(cy, (-1, 1))\n",
    "      cxy = tf.concat([cx, cy], axis=-1)\n",
    "      cxy = tf.tile(cxy, [1, n_anchors])\n",
    "      cxy = tf.reshape(cxy, [1, -1, 2])\n",
    "      strides = (input.shape[1] // out_shape[1],input.shape[2] // out_shape[2])\n",
    "      box_centers = (box_centers + cxy) * strides\n",
    "\n",
    "      prediction = tf.concat([box_centers, box_shapes, confidence, classes], axis=-1)\n",
    "      # prediction stored in (batch_size x image_dim*image_dim*anchor_num x (5 +  num_classes))\n",
    "\n",
    "      if scale == 0:\n",
    "        # print('hello')\n",
    "        out_pred = prediction\n",
    "        scale = 1\n",
    "      else:\n",
    "        out_pred = tf.concat([out_pred, prediction], axis=1)    \n",
    "    layers_cache.append(x)\n",
    "  model = tf.keras.Model(input,out_pred)\n",
    "  model.summary()\n",
    "  print(layers_cache)\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights loaded\n"
     ]
    }
   ],
   "source": [
    "def save_weights(model,weightfilepath,configfilepath):\n",
    "\n",
    "  weightfile = open(weightfilepath,\"rb\")\n",
    "\n",
    "  # skipping initial header values\n",
    "  np.fromfile(weightfile, dtype=np.int32, count=5)\n",
    "\n",
    "  # Now reading weights\n",
    "\n",
    "  block_list = get_blocks(configfilepath)\n",
    "\n",
    "  for i,block in enumerate(block_list[1:]):\n",
    "\n",
    "    if block['type'] == 'convolutional':\n",
    "\n",
    "      conv_layer = model.get_layer(f'conv_{i}')\n",
    "      print(\"layer: \",i+1,conv_layer)\n",
    "\n",
    "      filters = conv_layer.filters\n",
    "      kernel = conv_layer.kernel_size[0]\n",
    "      in_dim = conv_layer.input_shape[-1]\n",
    "      if \"batch_normalize\" in block:\n",
    "        # print(\"layer: \",i+1,norm_layer)\n",
    "        norm_layer =  model.get_layer(f'batch_norm_{i}')\n",
    "        print(\"layer: \",i+1,norm_layer)\n",
    "        batch_norm_weights = np.fromfile(weightfile, dtype=np.float32, count=4 * filters) #4*filters as batch norm will have the below weights\n",
    "        # tf [gamma, beta, mean, variance]\n",
    "        batch_norm_weights = batch_norm_weights.reshape((4, filters))[[1, 0, 2, 3]]\n",
    "      else:\n",
    "          conv_bias = np.fromfile(weightfile, dtype=np.float32, count=filters)\n",
    "\n",
    "      # darknet shape (out_dim, in_dim, height, width)\n",
    "      conv_shape = (filters, in_dim, kernel, kernel)\n",
    "      conv_weights = np.fromfile(weightfile,dtype = np.float32, count = np.prod(conv_shape))\n",
    "      # tf shape (height, width, in_dim, out_dim)\n",
    "      conv_weights = conv_weights.reshape(conv_shape).transpose([2, 3, 1, 0])\n",
    "\n",
    "      if \"batch_normalize\" in block:\n",
    "        norm_layer.set_weights(batch_norm_weights)\n",
    "        conv_layer.set_weights([conv_weights])\n",
    "      else:\n",
    "          conv_layer.set_weights([conv_weights, conv_bias])\n",
    "\n",
    "  weightfile.close()\n",
    "#   model.save_weights('/content/yolov3_weights.tf')\n",
    "#   print('weights saved in tensorflow format!!')\n",
    "print('weights loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(predictions,model_image_shape,iou_thresh,confidence_thresh,max_output_size,max_output_size_per_class):\n",
    "\n",
    "  bbox , confidence , classes = tf.split(predictions,[4,1,-1],axis = -1)\n",
    "  bbox /= model_image_shape[0]  #scaling shape to 0 to 1 for ease in rescaling to input image shape\n",
    "\n",
    "  scores = confidence * classes\n",
    "\n",
    "  boxes, scores, classes, valid_detections = \\\n",
    "        tf.image.combined_non_max_suppression(\n",
    "        boxes=tf.reshape(bbox, (tf.shape(bbox)[0], -1, 1, 4)), # first dim is batch_size , -1 will be the number of boxes \n",
    "        scores=tf.reshape(scores, (tf.shape(scores)[0], -1,tf.shape(scores)[-1])),\n",
    "        max_output_size_per_class=max_output_size_per_class,\n",
    "        max_total_size=max_output_size,\n",
    "        iou_threshold=iou_thresh,\n",
    "        score_threshold=confidence_thresh\n",
    "    ) \n",
    "  return boxes, scores, classes, valid_detections # Only the top valid_detections[i] entries in boxes[i], scores[i] and classes[i] are valid. The rest of the entries are zero paddings. [i] denotes the ith element in batch_size for us it will be 0\n",
    "\n",
    "\"\"\"\n",
    "Getting final predicitons of boxes and scores and classes from yolo predictions\n",
    "\"\"\"\n",
    "\n",
    "def output_boxes(predictions,model_image_shape,iou_thresh, confidence_thresh, max_output_size, max_output_size_per_class):\n",
    "    \n",
    "    # each is batch_size x grid_size*grid_size*anchor* (1 / 80 for classes)\n",
    "    center_x, center_y, width, height, confidence, classes = tf.split(predictions, [1, 1, 1, 1, 1, -1], axis=-1)\n",
    "    top_left_x = center_x - width / 2.0\n",
    "    top_left_y = center_y - height / 2.0\n",
    "    bottom_right_x = center_x + width / 2.0\n",
    "    bottom_right_y = center_y + height / 2.0\n",
    "    inputs = tf.concat([top_left_x, top_left_y, bottom_right_x,\n",
    "                        bottom_right_y, confidence, classes], axis=-1)\n",
    "    boxes,scores,classes,valid_detections = non_max_suppression(inputs, model_image_shape, iou_thresh, confidence_thresh, max_output_size,max_output_size_per_class)\n",
    "    return boxes,scores,classes,valid_detections\n",
    "  \n",
    "\"\"\"\n",
    "Given input image and final boxes, drawing boxes on image\n",
    "\"\"\"\n",
    "def draw_output_bbox(input_image,boxes,scores,classes,valid_detections,class_names):\n",
    "\n",
    "  # print(scores.shape)\n",
    "  boxes, scores, classes, valid_detections = boxes[0], scores[0], classes[0], valid_detections[0] #firsr dim is batch size --> batch size is 1\n",
    "  boxes = np.array(boxes)\n",
    "  img = input_image.copy()\n",
    "  for i in range(valid_detections):\n",
    "        x1y1 = tuple((boxes[i,0:2] * [img.shape[1],img.shape[0]]).astype(np.int32)) #rescaling to input image shape\n",
    "        x2y2 = tuple((boxes[i,2:4] * [img.shape[1],img.shape[0]]).astype(np.int32))\n",
    "        img = cv2.rectangle(img, (x1y1), (x2y2), (255,0,0), 2)\n",
    "        img = cv2.putText(img, '{} {:.4f}'.format(class_names[int(classes[i])], scores[i]),(x1y1), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 2)\n",
    "  \n",
    "  return img\n",
    "\n",
    "\"\"\"\n",
    "Loading Class Names from text file\n",
    "\"\"\"\n",
    "def load_class_names(classfilepath):\n",
    "  \n",
    "  with open(classfilepath, 'r') as file:\n",
    "        class_names = [line.rstrip('\\n') for line in file if line != '\\n']\n",
    "  return class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compilng all Functions and showing Output\n",
    "\"\"\"\n",
    "def initialize_model(configfilepath,weightfilepath):\n",
    "  model = create_model(configfilepath,model_image_shape)\n",
    "  save_weights(model,weightfilepath,configfilepath)\n",
    "  model.save('../output/yolo.h5')\n",
    "  # load_weights(model,configfilepath,weightfilepath)\n",
    "  return model\n",
    "def predict(input_image_path,model):\n",
    "\n",
    "  input_image = cv2.imread(input_image_path)\n",
    "  model_resized_image = cv2.resize(input_image,(model_image_shape[0],model_image_shape[1]))\n",
    "  # #we need to create the batch_size axis\n",
    "  input_to_model = tf.expand_dims(np.array(model_resized_image),axis = 0)\n",
    "  model_prediction = model.predict(input_to_model)\n",
    "  pred_boxes,pred_scores,pred_classes,pred_valid_detections = output_boxes(model_prediction,model_image_shape,iou_thresh, confidence_thresh,max_output_size, max_output_size_per_class)\n",
    "  # print(pred_valid_detections)\n",
    "  final_img = draw_output_bbox(input_image,pred_boxes,pred_scores,pred_classes,pred_valid_detections,class_names)\n",
    "  print('../output/' + input_image_path[8:-4] + '_output.jpg')\n",
    "  cv2.imshow('be amazed',final_img)\n",
    "  cv2.imwrite('../output/' + input_image_path[8:-4] + '_output.jpg',final_img)\n",
    "  cv2.waitKey(0)\n",
    "def predict_video(video_path,model,save = False):\n",
    "\n",
    "  # win_name = 'Be Amazed!!'\n",
    "  # cv2.namedWindow(win_name)\n",
    "  print('../output/output-videos/' + video_path[15:-4] + '_output.mp4')\n",
    "  video = cv2.VideoCapture(video_path)\n",
    "  frame_size = (int(video.get(cv2.CAP_PROP_FRAME_WIDTH)),int(video.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "  fps = video.get(cv2.CAP_PROP_FPS)\n",
    "  output_list = []\n",
    "  while True:\n",
    "    ret, frame = video.read()\n",
    "    if ret == False:\n",
    "      break\n",
    "    model_resized_image = cv2.resize(frame,(model_image_shape[0],model_image_shape[1]))\n",
    "    input_to_model = tf.expand_dims(np.array(model_resized_image),axis = 0)\n",
    "    model_prediction = model.predict(input_to_model)\n",
    "    pred_boxes,pred_scores,pred_classes,pred_valid_detections = output_boxes(model_prediction,model_image_shape,iou_thresh, confidence_thresh,max_output_size, max_output_size_per_class)\n",
    "    final_img = draw_output_bbox(frame,pred_boxes,pred_scores,pred_classes,pred_valid_detections,class_names)\n",
    "    output_list.append(final_img)\n",
    "    \n",
    "  video.release()\n",
    "  \n",
    "  if save == False:\n",
    "    for image in output_list:\n",
    "      cv2.imshow('be amazed',image)\n",
    "      key = cv2.waitKey(50)\n",
    "      if key == ord('q'):\n",
    "        break\n",
    "  else:\n",
    "    print(fps,frame_size)\n",
    "    out = cv2.VideoWriter('../output/' + video_path[15:-4] + '_output.mp4', cv2.VideoWriter_fourcc(*'MP4V'),fps, frame_size)\n",
    "    for frame in output_list:\n",
    "      out.write(np.array(frame))\n",
    "    out.release()\n",
    "    print('Output Video Saved!!')\n",
    "  \n",
    "  cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 416, 416, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv (TFOpLambda)   (None, 416, 416, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv_0 (Conv2D)                (None, 416, 416, 32  864         ['tf.math.truediv[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_norm_0 (BatchNormalizati  (None, 416, 416, 32  128        ['conv_0[0][0]']                 \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " leakyRLU_0 (LeakyReLU)         (None, 416, 416, 32  0           ['batch_norm_0[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPadding2D)  (None, 417, 417, 32  0          ['leakyRLU_0[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_1 (Conv2D)                (None, 208, 208, 64  18432       ['zero_padding2d[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_norm_1 (BatchNormalizati  (None, 208, 208, 64  256        ['conv_1[0][0]']                 \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " leakyRLU_1 (LeakyReLU)         (None, 208, 208, 64  0           ['batch_norm_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_2 (Conv2D)                (None, 208, 208, 32  2048        ['leakyRLU_1[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_norm_2 (BatchNormalizati  (None, 208, 208, 32  128        ['conv_2[0][0]']                 \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " leakyRLU_2 (LeakyReLU)         (None, 208, 208, 32  0           ['batch_norm_2[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_3 (Conv2D)                (None, 208, 208, 64  18432       ['leakyRLU_2[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_norm_3 (BatchNormalizati  (None, 208, 208, 64  256        ['conv_3[0][0]']                 \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " leakyRLU_3 (LeakyReLU)         (None, 208, 208, 64  0           ['batch_norm_3[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 208, 208, 64  0           ['leakyRLU_3[0][0]',             \n",
      "                                )                                 'leakyRLU_1[0][0]']             \n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadding2  (None, 209, 209, 64  0          ['add[0][0]']                    \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv_5 (Conv2D)                (None, 104, 104, 12  73728       ['zero_padding2d_1[0][0]']       \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_norm_5 (BatchNormalizati  (None, 104, 104, 12  512        ['conv_5[0][0]']                 \n",
      " on)                            8)                                                                \n",
      "                                                                                                  \n",
      " leakyRLU_5 (LeakyReLU)         (None, 104, 104, 12  0           ['batch_norm_5[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv_6 (Conv2D)                (None, 104, 104, 64  8192        ['leakyRLU_5[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_norm_6 (BatchNormalizati  (None, 104, 104, 64  256        ['conv_6[0][0]']                 \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " leakyRLU_6 (LeakyReLU)         (None, 104, 104, 64  0           ['batch_norm_6[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_7 (Conv2D)                (None, 104, 104, 12  73728       ['leakyRLU_6[0][0]']             \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_norm_7 (BatchNormalizati  (None, 104, 104, 12  512        ['conv_7[0][0]']                 \n",
      " on)                            8)                                                                \n",
      "                                                                                                  \n",
      " leakyRLU_7 (LeakyReLU)         (None, 104, 104, 12  0           ['batch_norm_7[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 104, 104, 12  0           ['leakyRLU_7[0][0]',             \n",
      "                                8)                                'leakyRLU_5[0][0]']             \n",
      "                                                                                                  \n",
      " conv_9 (Conv2D)                (None, 104, 104, 64  8192        ['add_1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_norm_9 (BatchNormalizati  (None, 104, 104, 64  256        ['conv_9[0][0]']                 \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " leakyRLU_9 (LeakyReLU)         (None, 104, 104, 64  0           ['batch_norm_9[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_10 (Conv2D)               (None, 104, 104, 12  73728       ['leakyRLU_9[0][0]']             \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_norm_10 (BatchNormalizat  (None, 104, 104, 12  512        ['conv_10[0][0]']                \n",
      " ion)                           8)                                                                \n",
      "                                                                                                  \n",
      " leakyRLU_10 (LeakyReLU)        (None, 104, 104, 12  0           ['batch_norm_10[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 104, 104, 12  0           ['leakyRLU_10[0][0]',            \n",
      "                                8)                                'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " zero_padding2d_2 (ZeroPadding2  (None, 105, 105, 12  0          ['add_2[0][0]']                  \n",
      " D)                             8)                                                                \n",
      "                                                                                                  \n",
      " conv_12 (Conv2D)               (None, 52, 52, 256)  294912      ['zero_padding2d_2[0][0]']       \n",
      "                                                                                                  \n",
      " batch_norm_12 (BatchNormalizat  (None, 52, 52, 256)  1024       ['conv_12[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_12 (LeakyReLU)        (None, 52, 52, 256)  0           ['batch_norm_12[0][0]']          \n",
      "                                                                                                  \n",
      " conv_13 (Conv2D)               (None, 52, 52, 128)  32768       ['leakyRLU_12[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_13 (BatchNormalizat  (None, 52, 52, 128)  512        ['conv_13[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_13 (LeakyReLU)        (None, 52, 52, 128)  0           ['batch_norm_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv_14 (Conv2D)               (None, 52, 52, 256)  294912      ['leakyRLU_13[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_14 (BatchNormalizat  (None, 52, 52, 256)  1024       ['conv_14[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_14 (LeakyReLU)        (None, 52, 52, 256)  0           ['batch_norm_14[0][0]']          \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 52, 52, 256)  0           ['leakyRLU_14[0][0]',            \n",
      "                                                                  'leakyRLU_12[0][0]']            \n",
      "                                                                                                  \n",
      " conv_16 (Conv2D)               (None, 52, 52, 128)  32768       ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_norm_16 (BatchNormalizat  (None, 52, 52, 128)  512        ['conv_16[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_16 (LeakyReLU)        (None, 52, 52, 128)  0           ['batch_norm_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv_17 (Conv2D)               (None, 52, 52, 256)  294912      ['leakyRLU_16[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_17 (BatchNormalizat  (None, 52, 52, 256)  1024       ['conv_17[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_17 (LeakyReLU)        (None, 52, 52, 256)  0           ['batch_norm_17[0][0]']          \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 52, 52, 256)  0           ['leakyRLU_17[0][0]',            \n",
      "                                                                  'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv_19 (Conv2D)               (None, 52, 52, 128)  32768       ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_norm_19 (BatchNormalizat  (None, 52, 52, 128)  512        ['conv_19[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_19 (LeakyReLU)        (None, 52, 52, 128)  0           ['batch_norm_19[0][0]']          \n",
      "                                                                                                  \n",
      " conv_20 (Conv2D)               (None, 52, 52, 256)  294912      ['leakyRLU_19[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_20 (BatchNormalizat  (None, 52, 52, 256)  1024       ['conv_20[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_20 (LeakyReLU)        (None, 52, 52, 256)  0           ['batch_norm_20[0][0]']          \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 52, 52, 256)  0           ['leakyRLU_20[0][0]',            \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv_22 (Conv2D)               (None, 52, 52, 128)  32768       ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_norm_22 (BatchNormalizat  (None, 52, 52, 128)  512        ['conv_22[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_22 (LeakyReLU)        (None, 52, 52, 128)  0           ['batch_norm_22[0][0]']          \n",
      "                                                                                                  \n",
      " conv_23 (Conv2D)               (None, 52, 52, 256)  294912      ['leakyRLU_22[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_23 (BatchNormalizat  (None, 52, 52, 256)  1024       ['conv_23[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_23 (LeakyReLU)        (None, 52, 52, 256)  0           ['batch_norm_23[0][0]']          \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 52, 52, 256)  0           ['leakyRLU_23[0][0]',            \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv_25 (Conv2D)               (None, 52, 52, 128)  32768       ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_norm_25 (BatchNormalizat  (None, 52, 52, 128)  512        ['conv_25[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_25 (LeakyReLU)        (None, 52, 52, 128)  0           ['batch_norm_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv_26 (Conv2D)               (None, 52, 52, 256)  294912      ['leakyRLU_25[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_26 (BatchNormalizat  (None, 52, 52, 256)  1024       ['conv_26[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_26 (LeakyReLU)        (None, 52, 52, 256)  0           ['batch_norm_26[0][0]']          \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 52, 52, 256)  0           ['leakyRLU_26[0][0]',            \n",
      "                                                                  'add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv_28 (Conv2D)               (None, 52, 52, 128)  32768       ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_norm_28 (BatchNormalizat  (None, 52, 52, 128)  512        ['conv_28[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_28 (LeakyReLU)        (None, 52, 52, 128)  0           ['batch_norm_28[0][0]']          \n",
      "                                                                                                  \n",
      " conv_29 (Conv2D)               (None, 52, 52, 256)  294912      ['leakyRLU_28[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_29 (BatchNormalizat  (None, 52, 52, 256)  1024       ['conv_29[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_29 (LeakyReLU)        (None, 52, 52, 256)  0           ['batch_norm_29[0][0]']          \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 52, 52, 256)  0           ['leakyRLU_29[0][0]',            \n",
      "                                                                  'add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " conv_31 (Conv2D)               (None, 52, 52, 128)  32768       ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_norm_31 (BatchNormalizat  (None, 52, 52, 128)  512        ['conv_31[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_31 (LeakyReLU)        (None, 52, 52, 128)  0           ['batch_norm_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv_32 (Conv2D)               (None, 52, 52, 256)  294912      ['leakyRLU_31[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_32 (BatchNormalizat  (None, 52, 52, 256)  1024       ['conv_32[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_32 (LeakyReLU)        (None, 52, 52, 256)  0           ['batch_norm_32[0][0]']          \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 52, 52, 256)  0           ['leakyRLU_32[0][0]',            \n",
      "                                                                  'add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " conv_34 (Conv2D)               (None, 52, 52, 128)  32768       ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_norm_34 (BatchNormalizat  (None, 52, 52, 128)  512        ['conv_34[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_34 (LeakyReLU)        (None, 52, 52, 128)  0           ['batch_norm_34[0][0]']          \n",
      "                                                                                                  \n",
      " conv_35 (Conv2D)               (None, 52, 52, 256)  294912      ['leakyRLU_34[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_35 (BatchNormalizat  (None, 52, 52, 256)  1024       ['conv_35[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_35 (LeakyReLU)        (None, 52, 52, 256)  0           ['batch_norm_35[0][0]']          \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 52, 52, 256)  0           ['leakyRLU_35[0][0]',            \n",
      "                                                                  'add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " zero_padding2d_3 (ZeroPadding2  (None, 53, 53, 256)  0          ['add_10[0][0]']                 \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv_37 (Conv2D)               (None, 26, 26, 512)  1179648     ['zero_padding2d_3[0][0]']       \n",
      "                                                                                                  \n",
      " batch_norm_37 (BatchNormalizat  (None, 26, 26, 512)  2048       ['conv_37[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_37 (LeakyReLU)        (None, 26, 26, 512)  0           ['batch_norm_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv_38 (Conv2D)               (None, 26, 26, 256)  131072      ['leakyRLU_37[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_38 (BatchNormalizat  (None, 26, 26, 256)  1024       ['conv_38[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_38 (LeakyReLU)        (None, 26, 26, 256)  0           ['batch_norm_38[0][0]']          \n",
      "                                                                                                  \n",
      " conv_39 (Conv2D)               (None, 26, 26, 512)  1179648     ['leakyRLU_38[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_39 (BatchNormalizat  (None, 26, 26, 512)  2048       ['conv_39[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_39 (LeakyReLU)        (None, 26, 26, 512)  0           ['batch_norm_39[0][0]']          \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 26, 26, 512)  0           ['leakyRLU_39[0][0]',            \n",
      "                                                                  'leakyRLU_37[0][0]']            \n",
      "                                                                                                  \n",
      " conv_41 (Conv2D)               (None, 26, 26, 256)  131072      ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_norm_41 (BatchNormalizat  (None, 26, 26, 256)  1024       ['conv_41[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_41 (LeakyReLU)        (None, 26, 26, 256)  0           ['batch_norm_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv_42 (Conv2D)               (None, 26, 26, 512)  1179648     ['leakyRLU_41[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_42 (BatchNormalizat  (None, 26, 26, 512)  2048       ['conv_42[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_42 (LeakyReLU)        (None, 26, 26, 512)  0           ['batch_norm_42[0][0]']          \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 26, 26, 512)  0           ['leakyRLU_42[0][0]',            \n",
      "                                                                  'add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_44 (Conv2D)               (None, 26, 26, 256)  131072      ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_norm_44 (BatchNormalizat  (None, 26, 26, 256)  1024       ['conv_44[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_44 (LeakyReLU)        (None, 26, 26, 256)  0           ['batch_norm_44[0][0]']          \n",
      "                                                                                                  \n",
      " conv_45 (Conv2D)               (None, 26, 26, 512)  1179648     ['leakyRLU_44[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_45 (BatchNormalizat  (None, 26, 26, 512)  2048       ['conv_45[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_45 (LeakyReLU)        (None, 26, 26, 512)  0           ['batch_norm_45[0][0]']          \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 26, 26, 512)  0           ['leakyRLU_45[0][0]',            \n",
      "                                                                  'add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_47 (Conv2D)               (None, 26, 26, 256)  131072      ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_norm_47 (BatchNormalizat  (None, 26, 26, 256)  1024       ['conv_47[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_47 (LeakyReLU)        (None, 26, 26, 256)  0           ['batch_norm_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv_48 (Conv2D)               (None, 26, 26, 512)  1179648     ['leakyRLU_47[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_48 (BatchNormalizat  (None, 26, 26, 512)  2048       ['conv_48[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_48 (LeakyReLU)        (None, 26, 26, 512)  0           ['batch_norm_48[0][0]']          \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 26, 26, 512)  0           ['leakyRLU_48[0][0]',            \n",
      "                                                                  'add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_50 (Conv2D)               (None, 26, 26, 256)  131072      ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_norm_50 (BatchNormalizat  (None, 26, 26, 256)  1024       ['conv_50[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_50 (LeakyReLU)        (None, 26, 26, 256)  0           ['batch_norm_50[0][0]']          \n",
      "                                                                                                  \n",
      " conv_51 (Conv2D)               (None, 26, 26, 512)  1179648     ['leakyRLU_50[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_51 (BatchNormalizat  (None, 26, 26, 512)  2048       ['conv_51[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_51 (LeakyReLU)        (None, 26, 26, 512)  0           ['batch_norm_51[0][0]']          \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 26, 26, 512)  0           ['leakyRLU_51[0][0]',            \n",
      "                                                                  'add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_53 (Conv2D)               (None, 26, 26, 256)  131072      ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_norm_53 (BatchNormalizat  (None, 26, 26, 256)  1024       ['conv_53[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_53 (LeakyReLU)        (None, 26, 26, 256)  0           ['batch_norm_53[0][0]']          \n",
      "                                                                                                  \n",
      " conv_54 (Conv2D)               (None, 26, 26, 512)  1179648     ['leakyRLU_53[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_54 (BatchNormalizat  (None, 26, 26, 512)  2048       ['conv_54[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_54 (LeakyReLU)        (None, 26, 26, 512)  0           ['batch_norm_54[0][0]']          \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 26, 26, 512)  0           ['leakyRLU_54[0][0]',            \n",
      "                                                                  'add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_56 (Conv2D)               (None, 26, 26, 256)  131072      ['add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_norm_56 (BatchNormalizat  (None, 26, 26, 256)  1024       ['conv_56[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_56 (LeakyReLU)        (None, 26, 26, 256)  0           ['batch_norm_56[0][0]']          \n",
      "                                                                                                  \n",
      " conv_57 (Conv2D)               (None, 26, 26, 512)  1179648     ['leakyRLU_56[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_57 (BatchNormalizat  (None, 26, 26, 512)  2048       ['conv_57[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_57 (LeakyReLU)        (None, 26, 26, 512)  0           ['batch_norm_57[0][0]']          \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 26, 26, 512)  0           ['leakyRLU_57[0][0]',            \n",
      "                                                                  'add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_59 (Conv2D)               (None, 26, 26, 256)  131072      ['add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_norm_59 (BatchNormalizat  (None, 26, 26, 256)  1024       ['conv_59[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_59 (LeakyReLU)        (None, 26, 26, 256)  0           ['batch_norm_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv_60 (Conv2D)               (None, 26, 26, 512)  1179648     ['leakyRLU_59[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_60 (BatchNormalizat  (None, 26, 26, 512)  2048       ['conv_60[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_60 (LeakyReLU)        (None, 26, 26, 512)  0           ['batch_norm_60[0][0]']          \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 26, 26, 512)  0           ['leakyRLU_60[0][0]',            \n",
      "                                                                  'add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " zero_padding2d_4 (ZeroPadding2  (None, 27, 27, 512)  0          ['add_18[0][0]']                 \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv_62 (Conv2D)               (None, 13, 13, 1024  4718592     ['zero_padding2d_4[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_norm_62 (BatchNormalizat  (None, 13, 13, 1024  4096       ['conv_62[0][0]']                \n",
      " ion)                           )                                                                 \n",
      "                                                                                                  \n",
      " leakyRLU_62 (LeakyReLU)        (None, 13, 13, 1024  0           ['batch_norm_62[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_63 (Conv2D)               (None, 13, 13, 512)  524288      ['leakyRLU_62[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_63 (BatchNormalizat  (None, 13, 13, 512)  2048       ['conv_63[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_63 (LeakyReLU)        (None, 13, 13, 512)  0           ['batch_norm_63[0][0]']          \n",
      "                                                                                                  \n",
      " conv_64 (Conv2D)               (None, 13, 13, 1024  4718592     ['leakyRLU_63[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_norm_64 (BatchNormalizat  (None, 13, 13, 1024  4096       ['conv_64[0][0]']                \n",
      " ion)                           )                                                                 \n",
      "                                                                                                  \n",
      " leakyRLU_64 (LeakyReLU)        (None, 13, 13, 1024  0           ['batch_norm_64[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 13, 13, 1024  0           ['leakyRLU_64[0][0]',            \n",
      "                                )                                 'leakyRLU_62[0][0]']            \n",
      "                                                                                                  \n",
      " conv_66 (Conv2D)               (None, 13, 13, 512)  524288      ['add_19[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_norm_66 (BatchNormalizat  (None, 13, 13, 512)  2048       ['conv_66[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_66 (LeakyReLU)        (None, 13, 13, 512)  0           ['batch_norm_66[0][0]']          \n",
      "                                                                                                  \n",
      " conv_67 (Conv2D)               (None, 13, 13, 1024  4718592     ['leakyRLU_66[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_norm_67 (BatchNormalizat  (None, 13, 13, 1024  4096       ['conv_67[0][0]']                \n",
      " ion)                           )                                                                 \n",
      "                                                                                                  \n",
      " leakyRLU_67 (LeakyReLU)        (None, 13, 13, 1024  0           ['batch_norm_67[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 13, 13, 1024  0           ['leakyRLU_67[0][0]',            \n",
      "                                )                                 'add_19[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_69 (Conv2D)               (None, 13, 13, 512)  524288      ['add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_norm_69 (BatchNormalizat  (None, 13, 13, 512)  2048       ['conv_69[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_69 (LeakyReLU)        (None, 13, 13, 512)  0           ['batch_norm_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv_70 (Conv2D)               (None, 13, 13, 1024  4718592     ['leakyRLU_69[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_norm_70 (BatchNormalizat  (None, 13, 13, 1024  4096       ['conv_70[0][0]']                \n",
      " ion)                           )                                                                 \n",
      "                                                                                                  \n",
      " leakyRLU_70 (LeakyReLU)        (None, 13, 13, 1024  0           ['batch_norm_70[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 13, 13, 1024  0           ['leakyRLU_70[0][0]',            \n",
      "                                )                                 'add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_72 (Conv2D)               (None, 13, 13, 512)  524288      ['add_21[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_norm_72 (BatchNormalizat  (None, 13, 13, 512)  2048       ['conv_72[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_72 (LeakyReLU)        (None, 13, 13, 512)  0           ['batch_norm_72[0][0]']          \n",
      "                                                                                                  \n",
      " conv_73 (Conv2D)               (None, 13, 13, 1024  4718592     ['leakyRLU_72[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_norm_73 (BatchNormalizat  (None, 13, 13, 1024  4096       ['conv_73[0][0]']                \n",
      " ion)                           )                                                                 \n",
      "                                                                                                  \n",
      " leakyRLU_73 (LeakyReLU)        (None, 13, 13, 1024  0           ['batch_norm_73[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 13, 13, 1024  0           ['leakyRLU_73[0][0]',            \n",
      "                                )                                 'add_21[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_75 (Conv2D)               (None, 13, 13, 512)  524288      ['add_22[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_norm_75 (BatchNormalizat  (None, 13, 13, 512)  2048       ['conv_75[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_75 (LeakyReLU)        (None, 13, 13, 512)  0           ['batch_norm_75[0][0]']          \n",
      "                                                                                                  \n",
      " conv_76 (Conv2D)               (None, 13, 13, 1024  4718592     ['leakyRLU_75[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_norm_76 (BatchNormalizat  (None, 13, 13, 1024  4096       ['conv_76[0][0]']                \n",
      " ion)                           )                                                                 \n",
      "                                                                                                  \n",
      " leakyRLU_76 (LeakyReLU)        (None, 13, 13, 1024  0           ['batch_norm_76[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_77 (Conv2D)               (None, 13, 13, 512)  524288      ['leakyRLU_76[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_77 (BatchNormalizat  (None, 13, 13, 512)  2048       ['conv_77[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_77 (LeakyReLU)        (None, 13, 13, 512)  0           ['batch_norm_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv_78 (Conv2D)               (None, 13, 13, 1024  4718592     ['leakyRLU_77[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_norm_78 (BatchNormalizat  (None, 13, 13, 1024  4096       ['conv_78[0][0]']                \n",
      " ion)                           )                                                                 \n",
      "                                                                                                  \n",
      " leakyRLU_78 (LeakyReLU)        (None, 13, 13, 1024  0           ['batch_norm_78[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_79 (Conv2D)               (None, 13, 13, 512)  524288      ['leakyRLU_78[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_79 (BatchNormalizat  (None, 13, 13, 512)  2048       ['conv_79[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_79 (LeakyReLU)        (None, 13, 13, 512)  0           ['batch_norm_79[0][0]']          \n",
      "                                                                                                  \n",
      " conv_84 (Conv2D)               (None, 13, 13, 256)  131072      ['leakyRLU_79[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_84 (BatchNormalizat  (None, 13, 13, 256)  1024       ['conv_84[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_84 (LeakyReLU)        (None, 13, 13, 256)  0           ['batch_norm_84[0][0]']          \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 26, 26, 256)  0           ['leakyRLU_84[0][0]']            \n",
      "                                                                                                  \n",
      " tf.concat_1 (TFOpLambda)       (None, 26, 26, 768)  0           ['up_sampling2d[0][0]',          \n",
      "                                                                  'add_18[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_87 (Conv2D)               (None, 26, 26, 256)  196608      ['tf.concat_1[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_87 (BatchNormalizat  (None, 26, 26, 256)  1024       ['conv_87[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_87 (LeakyReLU)        (None, 26, 26, 256)  0           ['batch_norm_87[0][0]']          \n",
      "                                                                                                  \n",
      " conv_88 (Conv2D)               (None, 26, 26, 512)  1179648     ['leakyRLU_87[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_88 (BatchNormalizat  (None, 26, 26, 512)  2048       ['conv_88[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_88 (LeakyReLU)        (None, 26, 26, 512)  0           ['batch_norm_88[0][0]']          \n",
      "                                                                                                  \n",
      " conv_89 (Conv2D)               (None, 26, 26, 256)  131072      ['leakyRLU_88[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_89 (BatchNormalizat  (None, 26, 26, 256)  1024       ['conv_89[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_89 (LeakyReLU)        (None, 26, 26, 256)  0           ['batch_norm_89[0][0]']          \n",
      "                                                                                                  \n",
      " conv_90 (Conv2D)               (None, 26, 26, 512)  1179648     ['leakyRLU_89[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_90 (BatchNormalizat  (None, 26, 26, 512)  2048       ['conv_90[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_90 (LeakyReLU)        (None, 26, 26, 512)  0           ['batch_norm_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv_91 (Conv2D)               (None, 26, 26, 256)  131072      ['leakyRLU_90[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_91 (BatchNormalizat  (None, 26, 26, 256)  1024       ['conv_91[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_91 (LeakyReLU)        (None, 26, 26, 256)  0           ['batch_norm_91[0][0]']          \n",
      "                                                                                                  \n",
      " conv_96 (Conv2D)               (None, 26, 26, 128)  32768       ['leakyRLU_91[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_96 (BatchNormalizat  (None, 26, 26, 128)  512        ['conv_96[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_96 (LeakyReLU)        (None, 26, 26, 128)  0           ['batch_norm_96[0][0]']          \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 52, 52, 128)  0          ['leakyRLU_96[0][0]']            \n",
      "                                                                                                  \n",
      " tf.concat_4 (TFOpLambda)       (None, 52, 52, 384)  0           ['up_sampling2d_1[0][0]',        \n",
      "                                                                  'add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_99 (Conv2D)               (None, 52, 52, 128)  49152       ['tf.concat_4[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_99 (BatchNormalizat  (None, 52, 52, 128)  512        ['conv_99[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " leakyRLU_99 (LeakyReLU)        (None, 52, 52, 128)  0           ['batch_norm_99[0][0]']          \n",
      "                                                                                                  \n",
      " conv_100 (Conv2D)              (None, 52, 52, 256)  294912      ['leakyRLU_99[0][0]']            \n",
      "                                                                                                  \n",
      " batch_norm_100 (BatchNormaliza  (None, 52, 52, 256)  1024       ['conv_100[0][0]']               \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " leakyRLU_100 (LeakyReLU)       (None, 52, 52, 256)  0           ['batch_norm_100[0][0]']         \n",
      "                                                                                                  \n",
      " conv_101 (Conv2D)              (None, 52, 52, 128)  32768       ['leakyRLU_100[0][0]']           \n",
      "                                                                                                  \n",
      " batch_norm_101 (BatchNormaliza  (None, 52, 52, 128)  512        ['conv_101[0][0]']               \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " leakyRLU_101 (LeakyReLU)       (None, 52, 52, 128)  0           ['batch_norm_101[0][0]']         \n",
      "                                                                                                  \n",
      " conv_102 (Conv2D)              (None, 52, 52, 256)  294912      ['leakyRLU_101[0][0]']           \n",
      "                                                                                                  \n",
      " batch_norm_102 (BatchNormaliza  (None, 52, 52, 256)  1024       ['conv_102[0][0]']               \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " leakyRLU_102 (LeakyReLU)       (None, 52, 52, 256)  0           ['batch_norm_102[0][0]']         \n",
      "                                                                                                  \n",
      " conv_103 (Conv2D)              (None, 52, 52, 128)  32768       ['leakyRLU_102[0][0]']           \n",
      "                                                                                                  \n",
      " batch_norm_103 (BatchNormaliza  (None, 52, 52, 128)  512        ['conv_103[0][0]']               \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv_80 (Conv2D)               (None, 13, 13, 1024  4718592     ['leakyRLU_79[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_92 (Conv2D)               (None, 26, 26, 512)  1179648     ['leakyRLU_91[0][0]']            \n",
      "                                                                                                  \n",
      " leakyRLU_103 (LeakyReLU)       (None, 52, 52, 128)  0           ['batch_norm_103[0][0]']         \n",
      "                                                                                                  \n",
      " batch_norm_80 (BatchNormalizat  (None, 13, 13, 1024  4096       ['conv_80[0][0]']                \n",
      " ion)                           )                                                                 \n",
      "                                                                                                  \n",
      " batch_norm_92 (BatchNormalizat  (None, 26, 26, 512)  2048       ['conv_92[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " conv_104 (Conv2D)              (None, 52, 52, 256)  294912      ['leakyRLU_103[0][0]']           \n",
      "                                                                                                  \n",
      " leakyRLU_80 (LeakyReLU)        (None, 13, 13, 1024  0           ['batch_norm_80[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leakyRLU_92 (LeakyReLU)        (None, 26, 26, 512)  0           ['batch_norm_92[0][0]']          \n",
      "                                                                                                  \n",
      " batch_norm_104 (BatchNormaliza  (None, 52, 52, 256)  1024       ['conv_104[0][0]']               \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv_81 (Conv2D)               (None, 13, 13, 255)  261375      ['leakyRLU_80[0][0]']            \n",
      "                                                                                                  \n",
      " conv_93 (Conv2D)               (None, 26, 26, 255)  130815      ['leakyRLU_92[0][0]']            \n",
      "                                                                                                  \n",
      " leakyRLU_104 (LeakyReLU)       (None, 52, 52, 256)  0           ['batch_norm_104[0][0]']         \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)        (None, 507, 85)      0           ['conv_81[0][0]']                \n",
      "                                                                                                  \n",
      " tf.reshape_1 (TFOpLambda)      (None, 2028, 85)     0           ['conv_93[0][0]']                \n",
      "                                                                                                  \n",
      " conv_105 (Conv2D)              (None, 52, 52, 255)  65535       ['leakyRLU_104[0][0]']           \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 507, 2)      0           ['tf.reshape[0][0]']             \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_4 (Sl  (None, 2028, 2)     0           ['tf.reshape_1[0][0]']           \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.reshape_2 (TFOpLambda)      (None, 8112, 85)     0           ['conv_105[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.sigmoid (TFOpLambda)   (None, 507, 2)       0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 507, 2)      0           ['tf.reshape[0][0]']             \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.math.sigmoid_3 (TFOpLambda)  (None, 2028, 2)     0           ['tf.__operators__.getitem_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_5 (Sl  (None, 2028, 2)     0           ['tf.reshape_1[0][0]']           \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_8 (Sl  (None, 8112, 2)     0           ['tf.reshape_2[0][0]']           \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 507, 2)      0           ['tf.math.sigmoid[0][0]']        \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.exp (TFOpLambda)       (None, 507, 2)       0           ['tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2 (Sl  (None, 507, 1)      0           ['tf.reshape[0][0]']             \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3 (Sl  (None, 507, 80)     0           ['tf.reshape[0][0]']             \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 2028, 2)     0           ['tf.math.sigmoid_3[0][0]']      \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.math.exp_1 (TFOpLambda)     (None, 2028, 2)      0           ['tf.__operators__.getitem_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_6 (Sl  (None, 2028, 1)     0           ['tf.reshape_1[0][0]']           \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_7 (Sl  (None, 2028, 80)    0           ['tf.reshape_1[0][0]']           \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.math.sigmoid_6 (TFOpLambda)  (None, 8112, 2)     0           ['tf.__operators__.getitem_8[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_9 (Sl  (None, 8112, 2)     0           ['tf.reshape_2[0][0]']           \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None, 507, 2)      0           ['tf.__operators__.add[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 507, 2)       0           ['tf.math.exp[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.sigmoid_1 (TFOpLambda)  (None, 507, 1)      0           ['tf.__operators__.getitem_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.math.sigmoid_2 (TFOpLambda)  (None, 507, 80)     0           ['tf.__operators__.getitem_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLambda  (None, 2028, 2)     0           ['tf.__operators__.add_1[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLambda  (None, 2028, 2)     0           ['tf.math.exp_1[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.sigmoid_4 (TFOpLambda)  (None, 2028, 1)     0           ['tf.__operators__.getitem_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.math.sigmoid_5 (TFOpLambda)  (None, 2028, 80)    0           ['tf.__operators__.getitem_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 8112, 2)     0           ['tf.math.sigmoid_6[0][0]']      \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.math.exp_2 (TFOpLambda)     (None, 8112, 2)      0           ['tf.__operators__.getitem_9[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_10 (S  (None, 8112, 1)     0           ['tf.reshape_2[0][0]']           \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_11 (S  (None, 8112, 80)    0           ['tf.reshape_2[0][0]']           \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (None, 507, 85)      0           ['tf.math.multiply_1[0][0]',     \n",
      "                                                                  'tf.math.multiply[0][0]',       \n",
      "                                                                  'tf.math.sigmoid_1[0][0]',      \n",
      "                                                                  'tf.math.sigmoid_2[0][0]']      \n",
      "                                                                                                  \n",
      " tf.concat_2 (TFOpLambda)       (None, 2028, 85)     0           ['tf.math.multiply_3[0][0]',     \n",
      "                                                                  'tf.math.multiply_2[0][0]',     \n",
      "                                                                  'tf.math.sigmoid_4[0][0]',      \n",
      "                                                                  'tf.math.sigmoid_5[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_5 (TFOpLambda  (None, 8112, 2)     0           ['tf.__operators__.add_2[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLambda  (None, 8112, 2)     0           ['tf.math.exp_2[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.sigmoid_7 (TFOpLambda)  (None, 8112, 1)     0           ['tf.__operators__.getitem_10[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.math.sigmoid_8 (TFOpLambda)  (None, 8112, 80)    0           ['tf.__operators__.getitem_11[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.concat_3 (TFOpLambda)       (None, 2535, 85)     0           ['tf.concat[0][0]',              \n",
      "                                                                  'tf.concat_2[0][0]']            \n",
      "                                                                                                  \n",
      " tf.concat_5 (TFOpLambda)       (None, 8112, 85)     0           ['tf.math.multiply_5[0][0]',     \n",
      "                                                                  'tf.math.multiply_4[0][0]',     \n",
      "                                                                  'tf.math.sigmoid_7[0][0]',      \n",
      "                                                                  'tf.math.sigmoid_8[0][0]']      \n",
      "                                                                                                  \n",
      " tf.concat_6 (TFOpLambda)       (None, 10647, 85)    0           ['tf.concat_3[0][0]',            \n",
      "                                                                  'tf.concat_5[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 62,001,757\n",
      "Trainable params: 61,949,149\n",
      "Non-trainable params: 52,608\n",
      "__________________________________________________________________________________________________\n",
      "[<KerasTensor: shape=(None, 416, 416, 32) dtype=float32 (created by layer 'leakyRLU_0')>, <KerasTensor: shape=(None, 208, 208, 64) dtype=float32 (created by layer 'leakyRLU_1')>, <KerasTensor: shape=(None, 208, 208, 32) dtype=float32 (created by layer 'leakyRLU_2')>, <KerasTensor: shape=(None, 208, 208, 64) dtype=float32 (created by layer 'leakyRLU_3')>, <KerasTensor: shape=(None, 208, 208, 64) dtype=float32 (created by layer 'add')>, <KerasTensor: shape=(None, 104, 104, 128) dtype=float32 (created by layer 'leakyRLU_5')>, <KerasTensor: shape=(None, 104, 104, 64) dtype=float32 (created by layer 'leakyRLU_6')>, <KerasTensor: shape=(None, 104, 104, 128) dtype=float32 (created by layer 'leakyRLU_7')>, <KerasTensor: shape=(None, 104, 104, 128) dtype=float32 (created by layer 'add_1')>, <KerasTensor: shape=(None, 104, 104, 64) dtype=float32 (created by layer 'leakyRLU_9')>, <KerasTensor: shape=(None, 104, 104, 128) dtype=float32 (created by layer 'leakyRLU_10')>, <KerasTensor: shape=(None, 104, 104, 128) dtype=float32 (created by layer 'add_2')>, <KerasTensor: shape=(None, 52, 52, 256) dtype=float32 (created by layer 'leakyRLU_12')>, <KerasTensor: shape=(None, 52, 52, 128) dtype=float32 (created by layer 'leakyRLU_13')>, <KerasTensor: shape=(None, 52, 52, 256) dtype=float32 (created by layer 'leakyRLU_14')>, <KerasTensor: shape=(None, 52, 52, 256) dtype=float32 (created by layer 'add_3')>, <KerasTensor: shape=(None, 52, 52, 128) dtype=float32 (created by layer 'leakyRLU_16')>, <KerasTensor: shape=(None, 52, 52, 256) dtype=float32 (created by layer 'leakyRLU_17')>, <KerasTensor: shape=(None, 52, 52, 256) dtype=float32 (created by layer 'add_4')>, <KerasTensor: shape=(None, 52, 52, 128) dtype=float32 (created by layer 'leakyRLU_19')>, <KerasTensor: shape=(None, 52, 52, 256) dtype=float32 (created by layer 'leakyRLU_20')>, <KerasTensor: shape=(None, 52, 52, 256) dtype=float32 (created by layer 'add_5')>, <KerasTensor: shape=(None, 52, 52, 128) dtype=float32 (created by layer 'leakyRLU_22')>, <KerasTensor: shape=(None, 52, 52, 256) dtype=float32 (created by layer 'leakyRLU_23')>, <KerasTensor: shape=(None, 52, 52, 256) dtype=float32 (created by layer 'add_6')>, <KerasTensor: shape=(None, 52, 52, 128) dtype=float32 (created by layer 'leakyRLU_25')>, <KerasTensor: shape=(None, 52, 52, 256) dtype=float32 (created by layer 'leakyRLU_26')>, <KerasTensor: shape=(None, 52, 52, 256) dtype=float32 (created by layer 'add_7')>, <KerasTensor: shape=(None, 52, 52, 128) dtype=float32 (created by layer 'leakyRLU_28')>, <KerasTensor: shape=(None, 52, 52, 256) dtype=float32 (created by layer 'leakyRLU_29')>, <KerasTensor: shape=(None, 52, 52, 256) dtype=float32 (created by layer 'add_8')>, <KerasTensor: shape=(None, 52, 52, 128) dtype=float32 (created by layer 'leakyRLU_31')>, <KerasTensor: shape=(None, 52, 52, 256) dtype=float32 (created by layer 'leakyRLU_32')>, <KerasTensor: shape=(None, 52, 52, 256) dtype=float32 (created by layer 'add_9')>, <KerasTensor: shape=(None, 52, 52, 128) dtype=float32 (created by layer 'leakyRLU_34')>, <KerasTensor: shape=(None, 52, 52, 256) dtype=float32 (created by layer 'leakyRLU_35')>, <KerasTensor: shape=(None, 52, 52, 256) dtype=float32 (created by layer 'add_10')>, <KerasTensor: shape=(None, 26, 26, 512) dtype=float32 (created by layer 'leakyRLU_37')>, <KerasTensor: shape=(None, 26, 26, 256) dtype=float32 (created by layer 'leakyRLU_38')>, <KerasTensor: shape=(None, 26, 26, 512) dtype=float32 (created by layer 'leakyRLU_39')>, <KerasTensor: shape=(None, 26, 26, 512) dtype=float32 (created by layer 'add_11')>, <KerasTensor: shape=(None, 26, 26, 256) dtype=float32 (created by layer 'leakyRLU_41')>, <KerasTensor: shape=(None, 26, 26, 512) dtype=float32 (created by layer 'leakyRLU_42')>, <KerasTensor: shape=(None, 26, 26, 512) dtype=float32 (created by layer 'add_12')>, <KerasTensor: shape=(None, 26, 26, 256) dtype=float32 (created by layer 'leakyRLU_44')>, <KerasTensor: shape=(None, 26, 26, 512) dtype=float32 (created by layer 'leakyRLU_45')>, <KerasTensor: shape=(None, 26, 26, 512) dtype=float32 (created by layer 'add_13')>, <KerasTensor: shape=(None, 26, 26, 256) dtype=float32 (created by layer 'leakyRLU_47')>, <KerasTensor: shape=(None, 26, 26, 512) dtype=float32 (created by layer 'leakyRLU_48')>, <KerasTensor: shape=(None, 26, 26, 512) dtype=float32 (created by layer 'add_14')>, <KerasTensor: shape=(None, 26, 26, 256) dtype=float32 (created by layer 'leakyRLU_50')>, <KerasTensor: shape=(None, 26, 26, 512) dtype=float32 (created by layer 'leakyRLU_51')>, <KerasTensor: shape=(None, 26, 26, 512) dtype=float32 (created by layer 'add_15')>, <KerasTensor: shape=(None, 26, 26, 256) dtype=float32 (created by layer 'leakyRLU_53')>, <KerasTensor: shape=(None, 26, 26, 512) dtype=float32 (created by layer 'leakyRLU_54')>, <KerasTensor: shape=(None, 26, 26, 512) dtype=float32 (created by layer 'add_16')>, <KerasTensor: shape=(None, 26, 26, 256) dtype=float32 (created by layer 'leakyRLU_56')>, <KerasTensor: shape=(None, 26, 26, 512) dtype=float32 (created by layer 'leakyRLU_57')>, <KerasTensor: shape=(None, 26, 26, 512) dtype=float32 (created by layer 'add_17')>, <KerasTensor: shape=(None, 26, 26, 256) dtype=float32 (created by layer 'leakyRLU_59')>, <KerasTensor: shape=(None, 26, 26, 512) dtype=float32 (created by layer 'leakyRLU_60')>, <KerasTensor: shape=(None, 26, 26, 512) dtype=float32 (created by layer 'add_18')>, <KerasTensor: shape=(None, 13, 13, 1024) dtype=float32 (created by layer 'leakyRLU_62')>, <KerasTensor: shape=(None, 13, 13, 512) dtype=float32 (created by layer 'leakyRLU_63')>, <KerasTensor: shape=(None, 13, 13, 1024) dtype=float32 (created by layer 'leakyRLU_64')>, <KerasTensor: shape=(None, 13, 13, 1024) dtype=float32 (created by layer 'add_19')>, <KerasTensor: shape=(None, 13, 13, 512) dtype=float32 (created by layer 'leakyRLU_66')>, <KerasTensor: shape=(None, 13, 13, 1024) dtype=float32 (created by layer 'leakyRLU_67')>, <KerasTensor: shape=(None, 13, 13, 1024) dtype=float32 (created by layer 'add_20')>, <KerasTensor: shape=(None, 13, 13, 512) dtype=float32 (created by layer 'leakyRLU_69')>, <KerasTensor: shape=(None, 13, 13, 1024) dtype=float32 (created by layer 'leakyRLU_70')>, <KerasTensor: shape=(None, 13, 13, 1024) dtype=float32 (created by layer 'add_21')>, <KerasTensor: shape=(None, 13, 13, 512) dtype=float32 (created by layer 'leakyRLU_72')>, <KerasTensor: shape=(None, 13, 13, 1024) dtype=float32 (created by layer 'leakyRLU_73')>, <KerasTensor: shape=(None, 13, 13, 1024) dtype=float32 (created by layer 'add_22')>, <KerasTensor: shape=(None, 13, 13, 512) dtype=float32 (created by layer 'leakyRLU_75')>, <KerasTensor: shape=(None, 13, 13, 1024) dtype=float32 (created by layer 'leakyRLU_76')>, <KerasTensor: shape=(None, 13, 13, 512) dtype=float32 (created by layer 'leakyRLU_77')>, <KerasTensor: shape=(None, 13, 13, 1024) dtype=float32 (created by layer 'leakyRLU_78')>, <KerasTensor: shape=(None, 13, 13, 512) dtype=float32 (created by layer 'leakyRLU_79')>, <KerasTensor: shape=(None, 13, 13, 1024) dtype=float32 (created by layer 'leakyRLU_80')>, <KerasTensor: shape=(None, 13, 13, 255) dtype=float32 (created by layer 'conv_81')>, <tf.Tensor: shape=(13,), dtype=float32, numpy=\n",
      "array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.],\n",
      "      dtype=float32)>, <KerasTensor: shape=(None, 13, 13, 512) dtype=float32 (created by layer 'leakyRLU_79')>, <KerasTensor: shape=(None, 13, 13, 256) dtype=float32 (created by layer 'leakyRLU_84')>, <KerasTensor: shape=(None, 26, 26, 256) dtype=float32 (created by layer 'up_sampling2d')>, <KerasTensor: shape=(None, 26, 26, 768) dtype=float32 (created by layer 'tf.concat_1')>, <KerasTensor: shape=(None, 26, 26, 256) dtype=float32 (created by layer 'leakyRLU_87')>, <KerasTensor: shape=(None, 26, 26, 512) dtype=float32 (created by layer 'leakyRLU_88')>, <KerasTensor: shape=(None, 26, 26, 256) dtype=float32 (created by layer 'leakyRLU_89')>, <KerasTensor: shape=(None, 26, 26, 512) dtype=float32 (created by layer 'leakyRLU_90')>, <KerasTensor: shape=(None, 26, 26, 256) dtype=float32 (created by layer 'leakyRLU_91')>, <KerasTensor: shape=(None, 26, 26, 512) dtype=float32 (created by layer 'leakyRLU_92')>, <KerasTensor: shape=(None, 26, 26, 255) dtype=float32 (created by layer 'conv_93')>, <tf.Tensor: shape=(26,), dtype=float32, numpy=\n",
      "array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.],\n",
      "      dtype=float32)>, <KerasTensor: shape=(None, 26, 26, 256) dtype=float32 (created by layer 'leakyRLU_91')>, <KerasTensor: shape=(None, 26, 26, 128) dtype=float32 (created by layer 'leakyRLU_96')>, <KerasTensor: shape=(None, 52, 52, 128) dtype=float32 (created by layer 'up_sampling2d_1')>, <KerasTensor: shape=(None, 52, 52, 384) dtype=float32 (created by layer 'tf.concat_4')>, <KerasTensor: shape=(None, 52, 52, 128) dtype=float32 (created by layer 'leakyRLU_99')>, <KerasTensor: shape=(None, 52, 52, 256) dtype=float32 (created by layer 'leakyRLU_100')>, <KerasTensor: shape=(None, 52, 52, 128) dtype=float32 (created by layer 'leakyRLU_101')>, <KerasTensor: shape=(None, 52, 52, 256) dtype=float32 (created by layer 'leakyRLU_102')>, <KerasTensor: shape=(None, 52, 52, 128) dtype=float32 (created by layer 'leakyRLU_103')>, <KerasTensor: shape=(None, 52, 52, 256) dtype=float32 (created by layer 'leakyRLU_104')>, <KerasTensor: shape=(None, 52, 52, 255) dtype=float32 (created by layer 'conv_105')>, <tf.Tensor: shape=(52,), dtype=float32, numpy=\n",
      "array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,\n",
      "       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,\n",
      "       39., 40., 41., 42., 43., 44., 45., 46., 47., 48., 49., 50., 51.],\n",
      "      dtype=float32)>]\n",
      "layer:  1 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E21D7FD30>\n",
      "layer:  1 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E21DA4DC0>\n",
      "layer:  2 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E01017580>\n",
      "layer:  2 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E21DCA400>\n",
      "layer:  3 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E21DCA4C0>\n",
      "layer:  3 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E21DCAD00>\n",
      "layer:  4 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E28095BE0>\n",
      "layer:  4 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E28095670>\n",
      "layer:  6 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E280ACC10>\n",
      "layer:  6 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E280B5490>\n",
      "layer:  7 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E280ACEE0>\n",
      "layer:  7 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E280C0910>\n",
      "layer:  8 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E280ACD90>\n",
      "layer:  8 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E280CA1C0>\n",
      "layer:  10 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E290A29A0>\n",
      "layer:  10 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E290A7AF0>\n",
      "layer:  11 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E280CA460>\n",
      "layer:  11 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E280C79A0>\n",
      "layer:  13 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E290BFC70>\n",
      "layer:  13 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E290A2640>\n",
      "layer:  14 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E290C7C40>\n",
      "layer:  14 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E290CAEB0>\n",
      "layer:  15 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E290BA730>\n",
      "layer:  15 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E290D88B0>\n",
      "layer:  17 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E290B3B50>\n",
      "layer:  17 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E21A68D60>\n",
      "layer:  18 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E280BA040>\n",
      "layer:  18 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E280C0E20>\n",
      "layer:  20 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E290B3E80>\n",
      "layer:  20 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E290B3D00>\n",
      "layer:  21 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E290CA850>\n",
      "layer:  21 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E290D8EB0>\n",
      "layer:  23 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E21DCA040>\n",
      "layer:  23 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E28085910>\n",
      "layer:  24 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E21DB0A90>\n",
      "layer:  24 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E290E0BE0>\n",
      "layer:  26 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E280CB070>\n",
      "layer:  26 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E280CB5E0>\n",
      "layer:  27 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E290EEAF0>\n",
      "layer:  27 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E290F0D60>\n",
      "layer:  29 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E290F90A0>\n",
      "layer:  29 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E290F46A0>\n",
      "layer:  30 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E290FFC70>\n",
      "layer:  30 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E29100EE0>\n",
      "layer:  32 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E29105220>\n",
      "layer:  32 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E291047F0>\n",
      "layer:  33 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E2910EDF0>\n",
      "layer:  33 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E29112850>\n",
      "layer:  35 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E291193A0>\n",
      "layer:  35 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E291164C0>\n",
      "layer:  36 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E290FF6A0>\n",
      "layer:  36 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E290D8A30>\n",
      "layer:  38 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E29127E50>\n",
      "layer:  38 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E29127F10>\n",
      "layer:  39 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E2912BC70>\n",
      "layer:  39 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E2912B700>\n",
      "layer:  40 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E29133EB0>\n",
      "layer:  40 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E29133910>\n",
      "layer:  42 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E291334F0>\n",
      "layer:  42 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E29133820>\n",
      "layer:  43 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E29137730>\n",
      "layer:  43 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E29142490>\n",
      "layer:  45 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E29158CD0>\n",
      "layer:  45 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E29142910>\n",
      "layer:  46 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E29169F70>\n",
      "layer:  46 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E291639A0>\n",
      "layer:  48 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E29163100>\n",
      "layer:  48 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E2917E850>\n",
      "layer:  49 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E29186760>\n",
      "layer:  49 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E291868B0>\n",
      "layer:  51 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E291999A0>\n",
      "layer:  51 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E2919E250>\n",
      "layer:  52 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E291A74C0>\n",
      "layer:  52 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E291A7340>\n",
      "layer:  54 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E29158340>\n",
      "layer:  54 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E29158EB0>\n",
      "layer:  55 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E29151FD0>\n",
      "layer:  55 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E29137A30>\n",
      "layer:  57 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E2919F520>\n",
      "layer:  57 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E2919FDC0>\n",
      "layer:  58 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E291B22E0>\n",
      "layer:  58 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E291B2AC0>\n",
      "layer:  60 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E291C1040>\n",
      "layer:  60 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E291C1790>\n",
      "layer:  61 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E291C8730>\n",
      "layer:  61 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E291C8700>\n",
      "layer:  63 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E291DFB20>\n",
      "layer:  63 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E291E73A0>\n",
      "layer:  64 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E291DB520>\n",
      "layer:  64 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E291DB490>\n",
      "layer:  65 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E291ED0D0>\n",
      "layer:  65 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E29200700>\n",
      "layer:  67 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E2920A8E0>\n",
      "layer:  67 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E291DFD00>\n",
      "layer:  68 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E291FC880>\n",
      "layer:  68 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E2920F940>\n",
      "layer:  70 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E291F12B0>\n",
      "layer:  70 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E291CD3A0>\n",
      "layer:  71 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E292181C0>\n",
      "layer:  71 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E291ACEB0>\n",
      "layer:  73 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E2915D490>\n",
      "layer:  73 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E291B3850>\n",
      "layer:  74 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E29221550>\n",
      "layer:  74 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E29228C40>\n",
      "layer:  76 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E2922ADF0>\n",
      "layer:  76 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E2922B4F0>\n",
      "layer:  77 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E2922EDC0>\n",
      "layer:  77 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E29234E50>\n",
      "layer:  78 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E2923BD30>\n",
      "layer:  78 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E29237D30>\n",
      "layer:  79 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E292261F0>\n",
      "layer:  79 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E2922E6D0>\n",
      "layer:  80 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E2923BEB0>\n",
      "layer:  80 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E2923BF10>\n",
      "layer:  81 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E2924B3A0>\n",
      "layer:  81 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E29247C10>\n",
      "layer:  82 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E1FBB3CD0>\n",
      "layer:  85 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E292475E0>\n",
      "layer:  85 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E2926BC10>\n",
      "layer:  88 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E292217C0>\n",
      "layer:  88 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E29234EE0>\n",
      "layer:  89 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E2922B3D0>\n",
      "layer:  89 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E29270940>\n",
      "layer:  90 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E29296580>\n",
      "layer:  90 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E292A1520>\n",
      "layer:  91 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E292BA580>\n",
      "layer:  91 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E2929DE80>\n",
      "layer:  92 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E292AC2E0>\n",
      "layer:  92 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E292BA3A0>\n",
      "layer:  93 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E292BA6D0>\n",
      "layer:  93 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E292BFEE0>\n",
      "layer:  94 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E292E17C0>\n",
      "layer:  97 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E292D0340>\n",
      "layer:  97 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E292E15E0>\n",
      "layer:  100 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E292C8BB0>\n",
      "layer:  100 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E29234F40>\n",
      "layer:  101 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E292B0220>\n",
      "layer:  101 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E29228F70>\n",
      "layer:  102 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E2929D190>\n",
      "layer:  102 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E292B08B0>\n",
      "layer:  103 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E2929D4F0>\n",
      "layer:  103 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E292F12B0>\n",
      "layer:  104 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E2930BF10>\n",
      "layer:  104 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E29306970>\n",
      "layer:  105 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E29306BE0>\n",
      "layer:  105 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x0000017E2931FAC0>\n",
      "layer:  106 <keras.layers.convolutional.conv2d.Conv2D object at 0x0000017E2930FD90>\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "class_names = load_class_names('../data/coco.names.txt')\n",
    "model = initialize_model(configfilepath,weightfilepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "class_names = load_class_names('../data/coco.names.txt')\n",
    "new_model = tf.keras.models.load_model('../output/yolo.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 394ms/step\n",
      "../output/test_output.jpg\n",
      "../output/output-videos/mumbai_traffic_output.mp4\n",
      "1/1 [==============================] - 0s 411ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "1/1 [==============================] - 0s 397ms/step\n",
      "1/1 [==============================] - 0s 450ms/step\n",
      "1/1 [==============================] - 0s 424ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 466ms/step\n",
      "1/1 [==============================] - 0s 413ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 387ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 450ms/step\n",
      "1/1 [==============================] - 0s 405ms/step\n",
      "1/1 [==============================] - 0s 407ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 457ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 381ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 390ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 380ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "1/1 [==============================] - 0s 398ms/step\n",
      "1/1 [==============================] - 0s 411ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 378ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 378ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 417ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 392ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 395ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 414ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 405ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 403ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 402ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 408ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 381ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 437ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 415ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 408ms/step\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "1/1 [==============================] - 0s 433ms/step\n",
      "1/1 [==============================] - 0s 380ms/step\n",
      "1/1 [==============================] - 0s 442ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 430ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 433ms/step\n",
      "1/1 [==============================] - 0s 459ms/step\n",
      "1/1 [==============================] - 0s 475ms/step\n",
      "1/1 [==============================] - 0s 480ms/step\n",
      "1/1 [==============================] - 1s 522ms/step\n",
      "1/1 [==============================] - 0s 454ms/step\n",
      "1/1 [==============================] - 0s 430ms/step\n",
      "1/1 [==============================] - 0s 468ms/step\n",
      "1/1 [==============================] - 0s 420ms/step\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 390ms/step\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 426ms/step\n",
      "1/1 [==============================] - 0s 380ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "1/1 [==============================] - 0s 425ms/step\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "1/1 [==============================] - 0s 432ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 393ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 455ms/step\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 428ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 409ms/step\n",
      "1/1 [==============================] - 0s 387ms/step\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 421ms/step\n",
      "1/1 [==============================] - 0s 380ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 394ms/step\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "1/1 [==============================] - 0s 408ms/step\n",
      "1/1 [==============================] - 0s 402ms/step\n",
      "1/1 [==============================] - 0s 394ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 387ms/step\n",
      "1/1 [==============================] - 0s 402ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 403ms/step\n",
      "1/1 [==============================] - 0s 378ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "1/1 [==============================] - 0s 490ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 399ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "1/1 [==============================] - 0s 402ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "1/1 [==============================] - 0s 372ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 393ms/step\n",
      "1/1 [==============================] - 1s 504ms/step\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 448ms/step\n",
      "1/1 [==============================] - 0s 468ms/step\n",
      "1/1 [==============================] - 0s 458ms/step\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 471ms/step\n",
      "1/1 [==============================] - 0s 443ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "1/1 [==============================] - 0s 421ms/step\n",
      "1/1 [==============================] - 0s 410ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 474ms/step\n",
      "1/1 [==============================] - 0s 390ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 410ms/step\n",
      "1/1 [==============================] - 0s 408ms/step\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 403ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 414ms/step\n",
      "1/1 [==============================] - 0s 418ms/step\n",
      "1/1 [==============================] - 0s 413ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 451ms/step\n",
      "1/1 [==============================] - 0s 419ms/step\n",
      "1/1 [==============================] - 0s 393ms/step\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 422ms/step\n",
      "1/1 [==============================] - 0s 381ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 405ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 404ms/step\n",
      "1/1 [==============================] - 1s 519ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 372ms/step\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 411ms/step\n",
      "1/1 [==============================] - 0s 411ms/step\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 378ms/step\n",
      "1/1 [==============================] - 0s 465ms/step\n",
      "1/1 [==============================] - 0s 457ms/step\n",
      "1/1 [==============================] - 1s 531ms/step\n",
      "1/1 [==============================] - 1s 558ms/step\n",
      "1/1 [==============================] - 0s 429ms/step\n",
      "1/1 [==============================] - 1s 549ms/step\n",
      "1/1 [==============================] - 0s 444ms/step\n",
      "1/1 [==============================] - 0s 429ms/step\n",
      "1/1 [==============================] - 0s 418ms/step\n",
      "1/1 [==============================] - 0s 393ms/step\n",
      "1/1 [==============================] - 0s 432ms/step\n",
      "1/1 [==============================] - 0s 444ms/step\n",
      "1/1 [==============================] - 0s 442ms/step\n",
      "1/1 [==============================] - 0s 432ms/step\n",
      "1/1 [==============================] - 0s 451ms/step\n",
      "1/1 [==============================] - 0s 442ms/step\n",
      "1/1 [==============================] - 0s 463ms/step\n",
      "1/1 [==============================] - 0s 468ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 372ms/step\n",
      "1/1 [==============================] - 0s 402ms/step\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 433ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 424ms/step\n",
      "1/1 [==============================] - 0s 404ms/step\n",
      "1/1 [==============================] - 1s 534ms/step\n",
      "1/1 [==============================] - 1s 585ms/step\n",
      "1/1 [==============================] - 0s 393ms/step\n",
      "1/1 [==============================] - 1s 546ms/step\n",
      "1/1 [==============================] - 1s 532ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 458ms/step\n",
      "1/1 [==============================] - 0s 441ms/step\n",
      "1/1 [==============================] - 0s 487ms/step\n",
      "1/1 [==============================] - 0s 484ms/step\n",
      "1/1 [==============================] - 0s 463ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 402ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 451ms/step\n",
      "1/1 [==============================] - 0s 390ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 372ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 372ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 463ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 446ms/step\n",
      "1/1 [==============================] - 0s 485ms/step\n",
      "1/1 [==============================] - 1s 780ms/step\n",
      "1/1 [==============================] - 1s 692ms/step\n",
      "1/1 [==============================] - 1s 509ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 404ms/step\n",
      "1/1 [==============================] - 0s 477ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 465ms/step\n",
      "1/1 [==============================] - 0s 455ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "1/1 [==============================] - 0s 431ms/step\n",
      "1/1 [==============================] - 0s 390ms/step\n",
      "1/1 [==============================] - 0s 408ms/step\n",
      "1/1 [==============================] - 0s 399ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 397ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 451ms/step\n",
      "1/1 [==============================] - 0s 451ms/step\n",
      "1/1 [==============================] - 0s 457ms/step\n",
      "1/1 [==============================] - 0s 472ms/step\n",
      "1/1 [==============================] - 0s 456ms/step\n",
      "1/1 [==============================] - 0s 487ms/step\n",
      "1/1 [==============================] - 0s 472ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 1s 512ms/step\n",
      "1/1 [==============================] - 1s 560ms/step\n",
      "1/1 [==============================] - 0s 474ms/step\n",
      "1/1 [==============================] - 0s 476ms/step\n",
      "1/1 [==============================] - 0s 416ms/step\n",
      "29.97002997002997 (1280, 720)\n",
      "Output Video Saved!!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"FINAL OUTPUT BLOCK\"\"\"\n",
    "predict(input_image_path,new_model)\n",
    "predict_video(video_path_comp,new_model,save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0187617260788 (1920, 1080)\n",
      "Output Video Saved!!\n"
     ]
    }
   ],
   "source": [
    "video_path_list = [video_path + './video2.mp4']\n",
    "for video_path in video_path_list:\n",
    "    predict_video(video_path,new_model,save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e31aef8222fb7c235d2ed8e74ce17e973738f89b37261e7466b7a63a6dfb1214"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
